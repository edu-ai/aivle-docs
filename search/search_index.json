{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"aiVLE - AI Virtual Learning Environment aiVLE is a complete solution for Creating reinforcement learning environment Evaluating reinforcement learning algorithms (i.e. agents) Hosting agent/bot competitions Getting Started Contributing to aiVLE","title":"Home"},{"location":"#aivle-ai-virtual-learning-environment","text":"aiVLE is a complete solution for Creating reinforcement learning environment Evaluating reinforcement learning algorithms (i.e. agents) Hosting agent/bot competitions Getting Started Contributing to aiVLE","title":"aiVLE - AI Virtual Learning Environment"},{"location":"dev-guide/","text":"Developer Guide In the developer guide, you may find information on how to deploy the website and worker cluster, and software architecture of the aiVLE platform. Deployment Guide Architecture Final year project report aiVLE Gym Design aiVLE Grader Design aiVLE Worker Design aiVLE Web Design","title":"Overview"},{"location":"dev-guide/#developer-guide","text":"In the developer guide, you may find information on how to deploy the website and worker cluster, and software architecture of the aiVLE platform. Deployment Guide","title":"Developer Guide"},{"location":"dev-guide/#architecture","text":"Final year project report aiVLE Gym Design aiVLE Grader Design aiVLE Worker Design aiVLE Web Design","title":"Architecture"},{"location":"dev-guide/deployment-guide/","text":"Deployment Guide There are three components that need deployment (links to corresponding GitHub repo): aiVLE Web aiVLE FE aiVLE Worker Deploying Frontend We have setup a Vercel CI in the GitHub repository - every update to the master branch will trigger an automatic deployment to the main domain, and every update to the pull request will trigger a preview deployment on a temporary domain. Deploying Backend Prepare Message Queue Broker The message queue broker we use is RabbitMQ . It is an essential dependency of Celery, the Python task queue library we use to distribute evaluation jobs among worker nodes. Therefore you need to have an accessible RabbitMQ instance ready before deploying aiVLE Web. If you want to deploy RabbitMQ yourself, please refer to the installation guide . If you want to use RabbitMQ as-a-service, you may take a look at CloudAQMP or Heroku . Either way you should get an address in the form amqp://{user}:{pass}@{host}:{port}/{vhost} , which we will refer to as BROKER_URI in the future. Note For the specification of AMQP URI, refer to RabbitMQ URI Specification . Warning It is possible for the default port 5671/5672 to be blocked in your network. In this case, you may consider deploying the RabbitMQ server in your local network. Or try changing the default port of RabbitMQ according to this guide . Deploy aiVLE Web You may follow the setup instruction on aiVLE Web Readme . There are a few extra things worth noting: Please generate your Django secret key randomly using tools like this and don't use common keys like secret_key . FRONTEND_URL should not have the trailing / . A valid example: https://aivle.leotan.cn EMAIL_HOST_PASSWORD is your app password if your Google account has 2-factor authentication enabled (assuming you are using Gmail as the email provider). Use this link to create an app password for aiVLE Web. DEFAULT_FROM_EMAIL will be the default sender field of your verification emails. For example, aiVLE No Reply <aivle.noreply@gmail.com> . After the deployment, you should be able to access the Django REST Framework page at the root domain (Django will automatically redirect you to domain.com/api/v1 ). The Django admin panel is accessible at domain.com/admin . Deploy aiVLE Worker aiVLE Worker is published as a PyPI package . Consequently, you may follow the Getting Started section of aiVLE Worker for the very easy setup process. You will see prompts like worker is ready once the client finished negotiation with the message queue system. What is ACCESS_TOKEN ? The aiVLE Web backend uses token-based authentication. In other words, in the API requests, we never attach the username and password along with the request. Instead, we provide an access token that can be invalidated easily without changing password for better security. Note You may also use aiVLE CLI to get the access token. To obtain an access token for your account, use POST /dj-rest-auth/login/ API with the following form fields: username password How to Test Connectivity with the Message Queue Broker? You may use the following code snippet ( pip install pika first): 1 2 3 4 5 6 import pika creds = pika . PlainCredentials ( username = 'guest' , password = 'guest' ) params = pika . ConnectionParameters ( host = 'localhost' , credentials = creds ) connection = pika . BlockingConnection ( params ) channel = connection . channel () You should receive a response from the broker server if the connection went through - it does not have to be a successful response!","title":"Deployment Guide"},{"location":"dev-guide/deployment-guide/#deployment-guide","text":"There are three components that need deployment (links to corresponding GitHub repo): aiVLE Web aiVLE FE aiVLE Worker","title":"Deployment Guide"},{"location":"dev-guide/deployment-guide/#deploying-frontend","text":"We have setup a Vercel CI in the GitHub repository - every update to the master branch will trigger an automatic deployment to the main domain, and every update to the pull request will trigger a preview deployment on a temporary domain.","title":"Deploying Frontend"},{"location":"dev-guide/deployment-guide/#deploying-backend","text":"","title":"Deploying Backend"},{"location":"dev-guide/deployment-guide/#prepare-message-queue-broker","text":"The message queue broker we use is RabbitMQ . It is an essential dependency of Celery, the Python task queue library we use to distribute evaluation jobs among worker nodes. Therefore you need to have an accessible RabbitMQ instance ready before deploying aiVLE Web. If you want to deploy RabbitMQ yourself, please refer to the installation guide . If you want to use RabbitMQ as-a-service, you may take a look at CloudAQMP or Heroku . Either way you should get an address in the form amqp://{user}:{pass}@{host}:{port}/{vhost} , which we will refer to as BROKER_URI in the future. Note For the specification of AMQP URI, refer to RabbitMQ URI Specification . Warning It is possible for the default port 5671/5672 to be blocked in your network. In this case, you may consider deploying the RabbitMQ server in your local network. Or try changing the default port of RabbitMQ according to this guide .","title":"Prepare Message Queue Broker"},{"location":"dev-guide/deployment-guide/#deploy-aivle-web","text":"You may follow the setup instruction on aiVLE Web Readme . There are a few extra things worth noting: Please generate your Django secret key randomly using tools like this and don't use common keys like secret_key . FRONTEND_URL should not have the trailing / . A valid example: https://aivle.leotan.cn EMAIL_HOST_PASSWORD is your app password if your Google account has 2-factor authentication enabled (assuming you are using Gmail as the email provider). Use this link to create an app password for aiVLE Web. DEFAULT_FROM_EMAIL will be the default sender field of your verification emails. For example, aiVLE No Reply <aivle.noreply@gmail.com> . After the deployment, you should be able to access the Django REST Framework page at the root domain (Django will automatically redirect you to domain.com/api/v1 ). The Django admin panel is accessible at domain.com/admin .","title":"Deploy aiVLE Web"},{"location":"dev-guide/deployment-guide/#deploy-aivle-worker","text":"aiVLE Worker is published as a PyPI package . Consequently, you may follow the Getting Started section of aiVLE Worker for the very easy setup process. You will see prompts like worker is ready once the client finished negotiation with the message queue system.","title":"Deploy aiVLE Worker"},{"location":"dev-guide/deployment-guide/#what-is-access_token","text":"The aiVLE Web backend uses token-based authentication. In other words, in the API requests, we never attach the username and password along with the request. Instead, we provide an access token that can be invalidated easily without changing password for better security. Note You may also use aiVLE CLI to get the access token. To obtain an access token for your account, use POST /dj-rest-auth/login/ API with the following form fields: username password","title":"What is ACCESS_TOKEN?"},{"location":"dev-guide/deployment-guide/#how-to-test-connectivity-with-the-message-queue-broker","text":"You may use the following code snippet ( pip install pika first): 1 2 3 4 5 6 import pika creds = pika . PlainCredentials ( username = 'guest' , password = 'guest' ) params = pika . ConnectionParameters ( host = 'localhost' , credentials = creds ) connection = pika . BlockingConnection ( params ) channel = connection . channel () You should receive a response from the broker server if the connection went through - it does not have to be a successful response!","title":"How to Test Connectivity with the Message Queue Broker?"},{"location":"user-guide/","text":"User Guide Note This guide is for end users, not administrators. If you need help on the deployment process, please go to Deployment Guide . aiVLE is short for AI Virtual Learning Environment. It is a platform for evaluating the performance of reinforcement learning algorithms. Since Python + OpenAI Gym is the most popular toolkit for both writing reinforcement learning environments and agents, aiVLE provides easy-to-use wrappers on top of existing OpenAI Gym environments and compatible agents for seamless migration from local/adhoc evaluation scripts to a online/reusable aiVLE Task . To prepare an aiVLE Task , generally you need to provide two parts: (Optional) an aiVLE Gym environment: follow Creating Your Environment to convert an existing Gym An aiVLE Grader test suite: see Creating Your Test Suite To validate your aiVLE Task before submitting to the platform, you may also want to take a look at Validating Sandbox to have a test-run of your entire package.","title":"Overview"},{"location":"user-guide/#user-guide","text":"Note This guide is for end users, not administrators. If you need help on the deployment process, please go to Deployment Guide . aiVLE is short for AI Virtual Learning Environment. It is a platform for evaluating the performance of reinforcement learning algorithms. Since Python + OpenAI Gym is the most popular toolkit for both writing reinforcement learning environments and agents, aiVLE provides easy-to-use wrappers on top of existing OpenAI Gym environments and compatible agents for seamless migration from local/adhoc evaluation scripts to a online/reusable aiVLE Task . To prepare an aiVLE Task , generally you need to provide two parts: (Optional) an aiVLE Gym environment: follow Creating Your Environment to convert an existing Gym An aiVLE Grader test suite: see Creating Your Test Suite To validate your aiVLE Task before submitting to the platform, you may also want to take a look at Validating Sandbox to have a test-run of your entire package.","title":"User Guide"},{"location":"user-guide/aivle-grader/","text":"Creating Your Test Suite GitHub repo Overview There are 3 components of user's concern: Agent : replaced by student's submission Evaluator : records the history of simulation, give scores from the history Test Cases : runs the underlying environment (Gym compatible is sufficient. I also provide examples on how to adapt aiVLE Gym environments. The process is very straightforward as aiVLE Gym is also Gym compatible.) with runtime and episode count limit, attaches evaluator to the simulation to produce evaluation results. A typical example of grader program looks like this: 1 2 3 4 5 env = gym . make ( \"...\" ) # any OpenAI Gym compatible environment is acceptable evaluator = RewardEvaluator () test_cases = [ ReinforcementLearningTestCase ( ... ), ... ] test_suite = TestSuite ( suite_id = \"...\" , cases = test_cases ) eval_result = test_suite . run ( create_agent ) Examples Please refer to the main function of aivle_gym_xxx.py in examples folder of aiVLE Grader repository. Documentation Agent abstract class To be considered a gradable agent, one needs to provide: step(state) : returns an action from observed state reset() : resets internal state for a new episode - reset is guaranteed to be called once before every episode Evaluator abstract class Note You may consider Evaluator as a storage of evaluation results (most of the time, equivalent to reward) for each episode/ run. At the end of evaluation (after n_runs episodes concluded), you can get a summary of this evaluation session using get_result() method. There are 4 abstract methods that need to be implemented: reset() : called once at the beginning of each run step(full_state: dict) : called once after taking one action in the environment. You should give everything you received from env.step in full_state argument. The evaluator will decide which information to use. get_result() : returns an EvaluationResult object that summarizes all executed episodes Built-in concrete class You may refer to these concrete implementations before creating your own custom concrete subclass. RewardEvaluator : computes average reward across episodes ensure reward field is provided in full_state StepCountEvaluator : computes average steps across episodes no special requirements TestCase abstract class There are 6 properties that need initialization: case_id time_limit n_runs : number of episodes to run agent_init : init params passed to __init__ method of Agent env : Gym compatible environment evaluator : Evaluator object There is one abstract method that needs to be implemented: run : runs the env environment for n_runs times with evaluator attached to the execution. Built-in concrete class You may refer to these concrete implementations before creating your own custom concrete subclass. ReinforcementLearningTestCase","title":"Creating Your Test Suite"},{"location":"user-guide/aivle-grader/#creating-your-test-suite","text":"GitHub repo","title":"Creating Your Test Suite"},{"location":"user-guide/aivle-grader/#overview","text":"There are 3 components of user's concern: Agent : replaced by student's submission Evaluator : records the history of simulation, give scores from the history Test Cases : runs the underlying environment (Gym compatible is sufficient. I also provide examples on how to adapt aiVLE Gym environments. The process is very straightforward as aiVLE Gym is also Gym compatible.) with runtime and episode count limit, attaches evaluator to the simulation to produce evaluation results. A typical example of grader program looks like this: 1 2 3 4 5 env = gym . make ( \"...\" ) # any OpenAI Gym compatible environment is acceptable evaluator = RewardEvaluator () test_cases = [ ReinforcementLearningTestCase ( ... ), ... ] test_suite = TestSuite ( suite_id = \"...\" , cases = test_cases ) eval_result = test_suite . run ( create_agent )","title":"Overview"},{"location":"user-guide/aivle-grader/#examples","text":"Please refer to the main function of aivle_gym_xxx.py in examples folder of aiVLE Grader repository.","title":"Examples"},{"location":"user-guide/aivle-grader/#documentation","text":"","title":"Documentation"},{"location":"user-guide/aivle-grader/#agent-abstract-class","text":"To be considered a gradable agent, one needs to provide: step(state) : returns an action from observed state reset() : resets internal state for a new episode - reset is guaranteed to be called once before every episode","title":"Agent abstract class"},{"location":"user-guide/aivle-grader/#evaluator-abstract-class","text":"Note You may consider Evaluator as a storage of evaluation results (most of the time, equivalent to reward) for each episode/ run. At the end of evaluation (after n_runs episodes concluded), you can get a summary of this evaluation session using get_result() method. There are 4 abstract methods that need to be implemented: reset() : called once at the beginning of each run step(full_state: dict) : called once after taking one action in the environment. You should give everything you received from env.step in full_state argument. The evaluator will decide which information to use. get_result() : returns an EvaluationResult object that summarizes all executed episodes","title":"Evaluator abstract class"},{"location":"user-guide/aivle-grader/#built-in-concrete-class","text":"You may refer to these concrete implementations before creating your own custom concrete subclass. RewardEvaluator : computes average reward across episodes ensure reward field is provided in full_state StepCountEvaluator : computes average steps across episodes no special requirements","title":"Built-in concrete class"},{"location":"user-guide/aivle-grader/#testcase-abstract-class","text":"There are 6 properties that need initialization: case_id time_limit n_runs : number of episodes to run agent_init : init params passed to __init__ method of Agent env : Gym compatible environment evaluator : Evaluator object There is one abstract method that needs to be implemented: run : runs the env environment for n_runs times with evaluator attached to the execution.","title":"TestCase abstract class"},{"location":"user-guide/aivle-grader/#built-in-concrete-class_1","text":"You may refer to these concrete implementations before creating your own custom concrete subclass. ReinforcementLearningTestCase","title":"Built-in concrete class"},{"location":"user-guide/aivle-gym/","text":"Creating Your Environment GitHub repo Getting Started We will call the original Gym environment the base environment in this tutorial. There are three components in an aiVLE Gym environment: serializer ( EnvSerializer ): translates certain non-JSON compatible Python objects into compatible ones, and in reverse agent env ( AgentEnv ): agent-side Gym-compatible class that communicates with the judge-side (simulation-side) judge env ( JudgeEnv / JudgeMultiEnv ): simulation environment, you may reuse existing Gym environment with little modification You will create concrete class of corresponding abstract base class by implementing certain abstract methods. (Also remember to call the base class constructor in __init__ method) Single-agent task We'll use Gym's built-in cart pole environment as an example: Serializer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class CartPoleEnvSerializer ( EnvSerializer ): def action_to_json ( self , action ): return action def json_to_action ( self , action_json ): return action_json '''Because numpy.array objects are not JSON-serializable by default, we provide custom methods to marshal/unmarshal observations. As shown in this example, if action/observation/info are JSON-serializable to begin with, you just return the original value. ''' def observation_to_json ( self , obs ): return obs . tolist () def json_to_observation ( self , obs_json ): return numpy . array ( obs_json ) def info_to_json ( self , info ): return info def json_to_info ( self , info_json ): return info_json Agent Environment 1 2 3 4 5 6 7 8 9 class CartPoleAgentEnv ( AgentEnv ): '''Instead of instantiating the base environment like in this example, since action/observation space and reward range are constants, you may use these constants directly when creating the agent environment. ''' def __init__ ( self ): base_env = gym . make ( 'CartPole-v0' ) super () . __init__ ( CartPoleEnvSerializer (), base_env . action_space , base_env . observation_space , base_env . reward_range , uid = 0 ) # uid can be any int for single-agent agent env Judge Environment As shown below, if you don't have special requirements, simply calling the corresponding methods in the base environment is good enough. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class CartPoleJudgeEnv ( JudgeEnv ): def __init__ ( self ): self . env = gym . make ( 'CartPole-v0' ) super () . __init__ ( CartPoleEnvSerializer (), self . env . action_space , self . env . observation_space , self . env . reward_range ) def step ( self , action ): return self . env . step ( action ) def reset ( self ): return self . env . reset () def render ( self , mode = 'human' ): return self . env . render ( mode = mode ) def close ( self ): self . env . close () def seed ( self , seed = None ): self . env . seed ( seed ) Agent Note that CartPoleAgentEnv() and gym.make('CartPole-v0') are designed to be interchangable in the agent code. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 use_aivle = True if use_aivle : env = CartPoleAgentEnv () else : env = gym . make ( 'CartPole-v0' ) for i_episode in range ( 10 ): env . reset () for t in range ( 100 ): env . render () action = env . action_space . sample () observation , reward , done , info = env . step ( action ) if done : break env . close () Execution These code can be found under ./example . To execute this concrete example: python judge.py to start the simulation process first python agent.py to run the agent code Multi-agent task Multi-agent case is very similar to single-agent case, differences are: agent env: action_space , observation_space and reward_range need to be that of this specific agent uid needs to be meaningful (i.e. unique among all participating agents, etc.) judge env: additional constructor params: n_agents : number of agents uid_to_idx : map from uid to agent index (0-indexed) A concrete example can be found under ./example/multi_agent.py and ./example/multi_judge.py","title":"Creating Your Environment"},{"location":"user-guide/aivle-gym/#creating-your-environment","text":"GitHub repo","title":"Creating Your Environment"},{"location":"user-guide/aivle-gym/#getting-started","text":"We will call the original Gym environment the base environment in this tutorial. There are three components in an aiVLE Gym environment: serializer ( EnvSerializer ): translates certain non-JSON compatible Python objects into compatible ones, and in reverse agent env ( AgentEnv ): agent-side Gym-compatible class that communicates with the judge-side (simulation-side) judge env ( JudgeEnv / JudgeMultiEnv ): simulation environment, you may reuse existing Gym environment with little modification You will create concrete class of corresponding abstract base class by implementing certain abstract methods. (Also remember to call the base class constructor in __init__ method)","title":"Getting Started"},{"location":"user-guide/aivle-gym/#single-agent-task","text":"We'll use Gym's built-in cart pole environment as an example:","title":"Single-agent task"},{"location":"user-guide/aivle-gym/#serializer","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class CartPoleEnvSerializer ( EnvSerializer ): def action_to_json ( self , action ): return action def json_to_action ( self , action_json ): return action_json '''Because numpy.array objects are not JSON-serializable by default, we provide custom methods to marshal/unmarshal observations. As shown in this example, if action/observation/info are JSON-serializable to begin with, you just return the original value. ''' def observation_to_json ( self , obs ): return obs . tolist () def json_to_observation ( self , obs_json ): return numpy . array ( obs_json ) def info_to_json ( self , info ): return info def json_to_info ( self , info_json ): return info_json","title":"Serializer"},{"location":"user-guide/aivle-gym/#agent-environment","text":"1 2 3 4 5 6 7 8 9 class CartPoleAgentEnv ( AgentEnv ): '''Instead of instantiating the base environment like in this example, since action/observation space and reward range are constants, you may use these constants directly when creating the agent environment. ''' def __init__ ( self ): base_env = gym . make ( 'CartPole-v0' ) super () . __init__ ( CartPoleEnvSerializer (), base_env . action_space , base_env . observation_space , base_env . reward_range , uid = 0 ) # uid can be any int for single-agent agent env","title":"Agent Environment"},{"location":"user-guide/aivle-gym/#judge-environment","text":"As shown below, if you don't have special requirements, simply calling the corresponding methods in the base environment is good enough. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class CartPoleJudgeEnv ( JudgeEnv ): def __init__ ( self ): self . env = gym . make ( 'CartPole-v0' ) super () . __init__ ( CartPoleEnvSerializer (), self . env . action_space , self . env . observation_space , self . env . reward_range ) def step ( self , action ): return self . env . step ( action ) def reset ( self ): return self . env . reset () def render ( self , mode = 'human' ): return self . env . render ( mode = mode ) def close ( self ): self . env . close () def seed ( self , seed = None ): self . env . seed ( seed )","title":"Judge Environment"},{"location":"user-guide/aivle-gym/#agent","text":"Note that CartPoleAgentEnv() and gym.make('CartPole-v0') are designed to be interchangable in the agent code. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 use_aivle = True if use_aivle : env = CartPoleAgentEnv () else : env = gym . make ( 'CartPole-v0' ) for i_episode in range ( 10 ): env . reset () for t in range ( 100 ): env . render () action = env . action_space . sample () observation , reward , done , info = env . step ( action ) if done : break env . close ()","title":"Agent"},{"location":"user-guide/aivle-gym/#execution","text":"These code can be found under ./example . To execute this concrete example: python judge.py to start the simulation process first python agent.py to run the agent code","title":"Execution"},{"location":"user-guide/aivle-gym/#multi-agent-task","text":"Multi-agent case is very similar to single-agent case, differences are: agent env: action_space , observation_space and reward_range need to be that of this specific agent uid needs to be meaningful (i.e. unique among all participating agents, etc.) judge env: additional constructor params: n_agents : number of agents uid_to_idx : map from uid to agent index (0-indexed) A concrete example can be found under ./example/multi_agent.py and ./example/multi_judge.py","title":"Multi-agent task"},{"location":"user-guide/aivle-worker/","text":"Validating Sandbox GitHub repo Create .env (if you only intend to test sandbox, put dummy values on the RHS is enough): Required fields 1 2 3 API_BASE_URL=... BROKER_URI=amqp://... ACCESS_TOKEN=... Optional fields (shown here are the default values) 1 2 3 4 TASK_QUEUE=gpu/private/default CELERY_CONCURRENCY=1 WORKER_NAME=celery ZMQ_PORT=15921 Under __main__.py , rewrite paths in start_sandbox() function, run that function. NOTE : There are three / in the URL (i.e. file:///home/... ) You need to use absolute path Details Referring to settings.py , by default the sandbox will load security profile from profiles/aivle-base.profile and the shell script to create new virtual environment will be scripts/create-venv.sh , and the temporary folder will be /tmp/aivle-worker . You don't need to change the settings if you're happy with the defaults. The basic steps aivle Worker takes to evaluate an agent in your task bundle are: Download and unzip task and agent archives Create a new virtual environment (and activate it) pip install -r requirements.txt (therefore in the root of your task bundle there must be a requirements.txt ) Inside the sandbox, run bash bootstrap.sh (similarly, bootstrap.sh comes from your task bundle)","title":"Validating Sandbox"},{"location":"user-guide/aivle-worker/#validating-sandbox","text":"GitHub repo Create .env (if you only intend to test sandbox, put dummy values on the RHS is enough): Required fields 1 2 3 API_BASE_URL=... BROKER_URI=amqp://... ACCESS_TOKEN=... Optional fields (shown here are the default values) 1 2 3 4 TASK_QUEUE=gpu/private/default CELERY_CONCURRENCY=1 WORKER_NAME=celery ZMQ_PORT=15921 Under __main__.py , rewrite paths in start_sandbox() function, run that function. NOTE : There are three / in the URL (i.e. file:///home/... ) You need to use absolute path","title":"Validating Sandbox"},{"location":"user-guide/aivle-worker/#details","text":"Referring to settings.py , by default the sandbox will load security profile from profiles/aivle-base.profile and the shell script to create new virtual environment will be scripts/create-venv.sh , and the temporary folder will be /tmp/aivle-worker . You don't need to change the settings if you're happy with the defaults. The basic steps aivle Worker takes to evaluate an agent in your task bundle are: Download and unzip task and agent archives Create a new virtual environment (and activate it) pip install -r requirements.txt (therefore in the root of your task bundle there must be a requirements.txt ) Inside the sandbox, run bash bootstrap.sh (similarly, bootstrap.sh comes from your task bundle)","title":"Details"}]}